---
---

@inproceedings{shihab2025hmae,
  title={HMAE: Self-Supervised Few-Shot Learning for Quantum Spin Systems},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  booktitle={ECAI 2025 -- 27th European Conference on Artificial Intelligence},
  series={Frontiers in Artificial Intelligence and Applications},
  volume={413},
  pages={1961--1968},
  publisher={IOS Press},
  year={2025},
  doi={10.3233/FAIA251031},
  selected={true},
  preview={ecai-logo.png}
}

@inproceedings{shihab-etal-2025-efficient,
  title={Efficient Unstructured Pruning of Mamba State-Space Models for Resource-Constrained Environments},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  editor={Christodoulopoulos, Christos and Chakraborty, Tanmoy and Rose, Carolyn and Peng, Violet},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  month=nov,
  year={2025},
  address={Suzhou, China},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2025.emnlp-main.562/},
  doi={10.18653/v1/2025.emnlp-main.562},
  pages={11109--11137},
  isbn={979-8-89176-332-6},
  abstract={As the deployment of AI models shifts towards edge devices, developing efficient sequence models has become critical. State-space models (SSMs), particularly Mamba, have emerged as strong rivals to Transformers due to their linear-time complexity and impressive performance across a range of tasks. However, their large parameter counts still hinder their use in resource-constrained environments. To address this, we propose a novel unstructured pruning framework specifically tailored for Mamba, achieving up to 70\% parameter reduction with only a 3--9\% drop in performance. Unlike pruning techniques designed for Transformers, our approach leverages Mamba's unique recurrent dynamics by incorporating pruning based on both weight and gradient importance to preserve critical parameters, a gradual pruning schedule to maintain model stability, and a global strategy to optimize parameter allocation across the model. Extensive experiments on the WikiText-103, Long Range Arena, and ETT benchmarks demonstrate significant efficiency gains, including 1.77× faster inference and a 46\% reduction in memory usage. Our component analysis confirms Mamba's robustness to pruning, highlighting the framework's potential for enabling practical deployment while underscoring the need for careful evaluation to avoid introducing biases in sensitive applications.},
  selected={true},
  preview={emnlp-logo.png}
}

@inproceedings{shihab-etal-2025-cache,
  title={Cache-Efficient Posterior Sampling for Reinforcement Learning with {LLM}-Derived Priors Across Discrete and Continuous Domains},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  editor={Christodoulopoulos, Christos and Chakraborty, Tanmoy and Rose, Carolyn and Peng, Violet},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  month=nov,
  year={2025},
  address={Suzhou, China},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2025.emnlp-main.560/},
  doi={10.18653/v1/2025.emnlp-main.560},
  pages={11062--11090},
  isbn={979-8-89176-332-6},
  abstract={Integrating large language models (LLMs) as action proposers in reinforcement learning (RL) significantly boosts performance in text-based environments but incurs prohibitive computational costs. We introduce a cache-efficient framework for Bayesian RL that leverages LLM-derived action suggestions, drastically reducing these costs while maintaining near-optimal performance. Our approach features an adaptive caching mechanism, optimized via meta-learning based on policy performance, to enable efficient inference across text-based games (e.g., TextWorld, ALFWorld) and robotic control tasks (e.g., MuJoCo, MetaWorld). This framework achieves a 3.8×--4.7× reduction in LLM queries and 4.0×--12.0× lower median latencies (85--93ms on consumer hardware), while retaining 96--98\% of the uncached policy's performance. We provide theoretical guarantees on the reliability of cached decisions with Kullback-Leibler (KL) divergence bounds, which are validated empirically by high success rates (90.4--95.6\%) in complex text environments. For offline RL, our proposed CQL-Prior variant improves performance by 14--29\% and reduces training time by 38--40\%. Evaluations across eight diverse tasks demonstrate the framework's generalizability and practicality for resource-constrained settings, making LLM-guided RL a viable and accessible approach for both text-based and robotic applications.},
  selected={true},
  preview={emnlp-logo.png}
}

@article{sivaraman2025clearvision,
  title={ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery},
  author={Sivaraman, Anush L. and Adu-Gyamfi, Kwadwo and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2504.19684},
  year={2025},
  note={Accepted to ITSC 2025},
  abbr={ITSC},
  preview={itsc-logo.png},
  arxiv={2504.19684}
}

@article{bhagat2025accuracy,
  title={Accuracy Is Not Agreement: Expert-Aligned Evaluation of Crash Narrative Classification Models},
  author={Bhagat, Sudesh Ramesh and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2504.13068},
  year={2025},
  note={Accepted to ITSC 2025},
  abbr={ITSC},
  preview={itsc-logo.png},
  arxiv={2504.13068}
}

@article{ahmed2025quantum,
  title={Quantum-driven Zero Trust Architecture with Dynamic Anomaly Detection in 7G Technology: A Neural Network Approach},
  author={Ahmed, Shakil and Shihab, Ibne Farabi and Khokhar, Ashfaq},
  journal={Measurement: Digitalization},
  pages={100005},
  year={2025},
  publisher={Elsevier},
  selected={true},
  preview={measurement-logo.png}
}

@inproceedings{rahman2024deeplocalization,
  title={Deeplocalization: Using Change Point Detection for Temporal Action Localization},
  author={Rahman, Mohammed Shaiqur and Shihab, Ibne Farabi and Chu, Lu and Sharma, Anuj},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024},
  abbr={CVPR},
  selected={true},
  preview={cvpr-logo.png}
}

@article{ferdous2024reinforcement,
  title={Reinforcement Learning-Guided Control Strategies for CAR T-Cell Activation and Expansion},
  author={Ferdous, Sakib and Shihab, Ibne Farabi and Chowdhury, Ratul and Reuel, Nigel F.},
  journal={Biotechnology and Bioengineering},
  volume={121},
  number={9},
  pages={2868--2880},
  year={2024},
  publisher={Wiley}
}

@inproceedings{shihab2023robust,
  title={Robust and Precise Sidewalk Detection with Ensemble Learning: Enhancing Road Safety and Facilitating Curb Space Management},
  author={Shihab, Ibne Farabi and Bhagat, Sudesh Ramesh and Sharma, Anuj},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
  pages={5092--5099},
  year={2023},
  organization={IEEE},
  doi={10.1109/ITSC57777.2023.10422138},
  abbr={ITSC},
  selected={true},
  preview={ITSC-logo-23.png}
}

@inproceedings{shihab2024leveraging,
  title={Leveraging Video-LLMs for Crash Detection and Narrative Generation: Performance Analysis and Challenges},
  author={Shihab, Ibne Farabi and Alvee, B. I. and Sharma, Anuj},
  booktitle={Proceedings of the TRC-30 Conference},
  year={2024}
}

@article{shihab2025fundamental,
  title={What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  journal={arXiv preprint arXiv:2509.03790},
  year={2025},
  note={Submitted to ICLR 2026},
  arxiv={2509.03790}
}

@article{shihab2025differentiable,
  title={Differentiable Entropy Regularization for Geometry and Neural Networks},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  journal={arXiv preprint arXiv:2509.03733},
  year={2025},
  note={Submitted to ICLR 2026},
  arxiv={2509.03733}
}

@article{akter2025counterfactual,
  title={Counterfactual Sensitivity for Faithful Reasoning in Language Models},
  author={Akter, Sanjeda and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2509.01544},
  year={2025},
  note={Submitted to ICLR 2026},
  arxiv={2509.01544}
}

@article{akter2025selective,
  title={Selective Risk Certification for LLM Outputs via Information-Lift Statistics: PAC-Bayes, Robustness, and Skeleton Design},
  author={Akter, Sanjeda and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2509.12527},
  year={2025},
  note={Submitted to ICLR 2026},
  arxiv={2509.12527}
}

@article{shihab2025crash,
  title={Crash Time Matters: HybridMamba for Fine-Grained Temporal Localization in Traffic Surveillance Footage},
  author={Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2504.03235},
  year={2025},
  note={Submitted to IEEE ITS Transaction},
  arxiv={2504.03235}
}

@article{akter2025image,
  title={Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems},
  author={Akter, Sanjeda and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2506.14096},
  year={2025},
  note={Submitted to IEEE ITS Transaction},
  arxiv={2506.14096}
}

@inproceedings{islam2022detecting,
  title={Detecting Faulty Machinery of Waste Water Treatment Plant Using Statistical Analysis \& Machine Learning},
  author={Islam, Md. Mazed Ul and Mondal, Joyanta J. and Shihab, Ibne Farabi},
  booktitle={2022 25th International Conference on Computer and Information Technology (ICCIT)},
  year={2022},
  organization={IEEE}
}

@article{ferdous2022effects,
  title={Effects of Sequence Features on Machine-Learned Enzyme Classification Fidelity},
  author={Ferdous, Sakib and Shihab, Ibne Farabi and Reuel, Nigel F.},
  journal={Biochemical Engineering Journal},
  volume={187},
  pages={108612},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{shihab2018machine,
  title={A Machine Learning Approach to Suggest Ideal Geographical Location for New Restaurant Establishment},
  author={Shihab, Ibne Farabi and Oishi, Maliha Moonwara and Islam, Samiul and Banik, Kalyan and Arif, Hossain},
  booktitle={2018 IEEE Region 10 Humanitarian Technology Conference (R10-HTC)},
  pages={1--5},
  year={2018},
  organization={IEEE}
}

@article{shihab2025detecting,
  title={Detecting and Mitigating Reward Hacking in Reinforcement Learning Systems: A Comprehensive Empirical Study},
  author={Shihab, Ibne Farabi and Akter, Sanjeda and Sharma, Anuj},
  journal={arXiv preprint arXiv:2507.XXXX},
  year={2025},
  note={Submitted to ICSE 2026}
}

@article{bhagat2025identification,
  title={Identification of Potentially Misclassified Crash Narratives using Machine Learning (ML) and Deep Learning (DL)},
  author={Bhagat, Sudesh and Shihab, Ibne Farabi and Wood, J.},
  journal={arXiv preprint arXiv:2507.03066},
  year={2025},
  arxiv={2507.03066}
}

@article{akter2025large,
  title={Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges},
  author={Akter, Sanjeda and Shihab, Ibne Farabi and Sharma, Anuj},
  journal={arXiv preprint arXiv:2507.02074},
  year={2025},
  arxiv={2507.02074}
}

@article{bhagat2025unlocking,
  title={Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment},
  author={Bhagat, Sudesh and Kandiboina, R. and Shihab, Ibne Farabi and Knickerbocker, S. and Hawkins, N. and Sharma, Anuj},
  journal={arXiv preprint arXiv:2506.19342},
  year={2025},
  note={Submitted to Journal of Safety Research},
  arxiv={2506.19342}
}
